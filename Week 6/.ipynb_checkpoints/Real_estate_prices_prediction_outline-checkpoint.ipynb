{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c2045ec",
   "metadata": {},
   "source": [
    "this is an outline notebook- sections are suggested steps, but more or less steps can be followed to reach your end goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-month",
   "metadata": {},
   "source": [
    "# Regression problem -  predicting real estate prices in USD\n",
    "\n",
    "\n",
    "#### Background: \n",
    "You are working as an analyst for a real estate company. Your company wants to build a machine learning model to predict the selling prices of houses based on a variety of features on which the value of the house is evaluated.\n",
    "\n",
    "#### Objective: \n",
    "The task is to build a model that will predict the price of a house based on features provided in the dataset. The senior management also wants to explore the characteristics of the houses which have the greatest impact on price, eg. understanding which factors are responsible for the highest property values - USD650K and above. \n",
    "\n",
    "#### Data: \n",
    "The data set consists of information on some 22,000 properties.  The dataset consisted of historic data for houses sold between May 2014 to May 2015. \n",
    "\n",
    "#### Definitions \n",
    "These are the definitions of data variables provided: (Note: For some of the variables that are self explanatory, no definition has been provided)\n",
    "\n",
    "+ Id: Unique identification number for the property.\n",
    "+ date: date the house was sold.\n",
    "+ price: price of the house.\n",
    "+ waterfront: house which has a view to a waterfront.\n",
    "+ condition: How good the condition is (overall). 1 indicates worn out property and 5 excellent.\n",
    "+ view: does the property have a view? and of what quality?\n",
    "+ grade: Overall grade given to the housing unit, based on King County grading system. 1 poor ,13 excellent.\n",
    "+ Sqft_above: square footage of house apart from basement.\n",
    "+ Sqft_living15: Living room area in 2015(implies - some renovations). This might or might not have affected the lotsize area.\n",
    "+ Sqft_lot15: lotSize area in 2015(implies - some renovations).\n",
    "\n",
    "#### Exploring the data\n",
    "We encourage you to thoroughly understand your data and take the necessary steps to prepare your data for modeling before building exploratory or predictive models. \n",
    "To explore the data, you can use the techniques such as data profiling packages, Tableau ad hoc analysis, or any other EDA method including describe, info, sumna, using matplotlib and seaborn for distribution and correlation visualisations.\n",
    "\n",
    "The data has a number of categorical and numerical variables. Explore the nature of data for these variables before you start with the data cleaning process and then proceed to data pre-processing (scaling numerical variables and encoding categorical variables). \n",
    "\n",
    "#### Model\n",
    "You may use different models to compare the accuracies and find the model that best fits your data. Since this is a regression problem (predicting a value), you can use linear regression, KNN, tree based regression models. You can use the measures of accuracies that have been discussed in class. \n",
    "\n",
    "Please note that while comparing different models, make sure you use the same measure of accuracy as a benchmark and the appropriate metrics for that model- see the sklearn documentation for details.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daily-planner",
   "metadata": {},
   "source": [
    "### import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-flavor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy and pandas, matplotlib and seaborn, scipy, sklearn model and metrics \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29690e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-cloud",
   "metadata": {},
   "source": [
    "### read data as a pandas data frame, preview top 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778c911e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254b35ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "reduced-jamaica",
   "metadata": {},
   "source": [
    "### EDA - exploratory data analysis - get to know the data \n",
    "\n",
    "We are particularly keen to understand the data types (and if those data types are appropriate), if there are any null, 0 or missing values, if the meaning of each feature is clear and the data is all clean and usable, if any new useful features could be created - such as creating buckets of values from columns, what relationships can we perceive between features, do we have any duplicates (check the ID column), if any outliers seem unreasonable/extreme and could be removed, if any columns might reasonably be dropped\n",
    "\n",
    "Note down every identified cleaning, wrangling or pre processing task that could be attempted at this stage or later in your notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-biotechnology",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd44be68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48db2db8",
   "metadata": {},
   "source": [
    "### histograms or boxplots\n",
    "\n",
    "1) identify how much rescaling might be needed and if any outliers or skewing will be a problem, per every numerical column. Remember that linear regression doesnt perform well with highly skewed data so normalisation method would be needed. \n",
    "\n",
    "2) bar charts for each categorical column to see the range and spread of that data too - remembering that linear regression requires all numeric data points for the training data set, we would have to later use OHE / get_dummies to convert categories. If we have too many unique values, is there a rationale for grouping them and therefore saving redundant columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ffe825",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccec3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a815b79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d139d943",
   "metadata": {},
   "source": [
    "### Check for multicollinearity \n",
    "\n",
    "depending on the model chosen, multicollinearity can impact the accuracy of the model algoritm by giving too much importance to similar features. Reduce this risk by creating the correlation matrix, consider dropping any one of two very similar numerical features, judging by their correlation score (spearmans or pearsons) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7d7974",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b78ead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "responsible-drive",
   "metadata": {},
   "source": [
    "### Clean and wrangling steps "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e500d8",
   "metadata": {},
   "source": [
    "#### List here any cleaning or wrangling steps to return to on a second iteration of your model \n",
    "\n",
    "\n",
    "+ \n",
    "+ \n",
    "+ \n",
    "+ \n",
    "+ \n",
    "+ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2199a4c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e29550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6176687c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38cf2e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598ed037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eea34a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "reduced-teaching",
   "metadata": {},
   "source": [
    "### split off the dependant variable (label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8771bfff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b179c84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0608477c",
   "metadata": {},
   "source": [
    "### Pre processing - iteration 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326631f4",
   "metadata": {},
   "source": [
    "+ the minimum requirements here depend on the model chosen. ie, for linear regression you must label / encode any categorical (object type) columns, nulls must also have been eliminated at this stage - as the model only works with numbers. \n",
    "\n",
    "at this stage it is possible to proceed to your baseline (worst case) model\n",
    "\n",
    "---- \n",
    "OR \n",
    "\n",
    "+ you can consider applying a scaling method for the numerical features\n",
    "+ this is best applied after dealing with any extreme outlier values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f55b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-motion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af05d3fa",
   "metadata": {},
   "source": [
    "### import the chosen model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ba0f33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b541d09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a84635b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd937f48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "improving-article",
   "metadata": {},
   "source": [
    "### train test split - select a % test data set and set your random seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-poster",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e5f9ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-moore",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ruled-management",
   "metadata": {},
   "source": [
    "### apply model and train model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82f631f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bfd6a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47151ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-depth",
   "metadata": {},
   "source": [
    "### evaluate accuracy against test dataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-marker",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-booking",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-solid",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "faa370ec",
   "metadata": {},
   "source": [
    "#### next steps\n",
    "\n",
    "+ Consider the accuracy of predictions, especially the Rsquared and MAE (which in this case describes in dollars, how far away from predicting an accurate house price your model is)\n",
    "\n",
    "+ also think about - is there anything I could return to to improve my model accuracy?? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82b0878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7aa7fb60",
   "metadata": {},
   "source": [
    "### Pre processing iteration 2 & 3 and ... \n",
    "\n",
    "It is best to attempt at least two more experimental rounds of pre processing in order to run the models and compare the results. This time, you could be more selective in your features, do more feature engineering or data wrangling, use a different method for imputing nulls/ dealing with outliers, apply a couple of different scaling method to numerical columns to normalise their distribution or convert numerical features to categories in a logical way "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749e230b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57676002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1032256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5896af40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0452e38",
   "metadata": {},
   "source": [
    "### train test split - select a % test data set and set your random seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f8ee22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13be341c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc476d36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb13ee83",
   "metadata": {},
   "source": [
    "### apply model and train model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c335eb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03aafe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f5d915",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "739d033e",
   "metadata": {},
   "source": [
    "### evaluate accuracy against test dataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10c9803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9cbba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25704331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe0ae95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ab152f1",
   "metadata": {},
   "source": [
    "### Compare, visually or in a summary cell, your regression model metrics for each iteration. \n",
    "\n",
    "+ Which model and techniques combined worked best? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441a1537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fc1927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ee719a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264f2864",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
